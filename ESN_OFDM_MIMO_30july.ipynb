{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568fd874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
    "    gpu_num = 0\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    import os\n",
    "    os.system(\"pip install sionna==0.19\")\n",
    "    import sionna\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "sionna.config.seed = 42\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, LayerNormalization\n",
    "from tensorflow.nn import relu\n",
    "\n",
    "from sionna.channel.tr38901 import Antenna, AntennaArray, CDL\n",
    "from sionna.channel import OFDMChannel\n",
    "from sionna.mimo import StreamManagement\n",
    "from sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEEqualizer, RemoveNulledSubcarriers, ResourceGridDemapper\n",
    "from sionna.utils import BinarySource, ebnodb2no, insert_dims, flatten_last_dims, log10, expand_to_rank\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.mapping import Mapper, Demapper\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from sionna.utils import sim_ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbba1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_frequency = 3.5e9\n",
    "delay_spread = 100e-9\n",
    "cdl_model = \"C\"\n",
    "speed = 10.0\n",
    "ebno_db_min = -5.0\n",
    "ebno_db_max = 10.0\n",
    "\n",
    "subcarrier_spacing = 30e3\n",
    "fft_size = 128\n",
    "num_ofdm_symbols = 14\n",
    "dc_null = True\n",
    "num_guard_carriers = [5, 6]\n",
    "pilot_pattern = \"kronecker\"\n",
    "pilot_ofdm_symbol_indices = [2, 11]\n",
    "cyclic_prefix_length = 0\n",
    "\n",
    "num_bits_per_symbol = 2\n",
    "coderate = 0.5\n",
    "\n",
    "num_conv_channels = 128\n",
    "\n",
    "num_training_iterations = 3000\n",
    "training_batch_size = 128\n",
    "model_weights_path = \"neural_receiver_weights\"\n",
    "\n",
    "results_filename = \"neural_receiver_results\"\n",
    "\n",
    "stream_manager = StreamManagement(np.array([[1]]), 1)\n",
    "\n",
    "resource_grid = ResourceGrid(num_ofdm_symbols = num_ofdm_symbols,\n",
    "                             fft_size = fft_size,\n",
    "                             subcarrier_spacing = subcarrier_spacing,\n",
    "                             num_tx = 1,\n",
    "                             num_streams_per_tx = 1,\n",
    "                             cyclic_prefix_length = cyclic_prefix_length,\n",
    "                             dc_null = dc_null,\n",
    "                             pilot_pattern = pilot_pattern,\n",
    "                             pilot_ofdm_symbol_indices = pilot_ofdm_symbol_indices,\n",
    "                             num_guard_carriers = num_guard_carriers)\n",
    "\n",
    "n = int(resource_grid.num_data_symbols * num_bits_per_symbol)\n",
    "k = int(n * coderate)\n",
    "\n",
    "ut_antenna = Antenna(polarization=\"single\",\n",
    "                     polarization_type=\"V\",\n",
    "                     antenna_pattern=\"38.901\",\n",
    "                     carrier_frequency=carrier_frequency)\n",
    "\n",
    "bs_array = AntennaArray(num_rows=1,\n",
    "                        num_cols=1,\n",
    "                        polarization=\"dual\",\n",
    "                        polarization_type=\"VH\",\n",
    "                        antenna_pattern=\"38.901\",\n",
    "                        carrier_frequency=carrier_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c3c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transmitter\n",
    "binary_source = BinarySource()\n",
    "mapper = Mapper(\"qam\", num_bits_per_symbol)\n",
    "rg_mapper = ResourceGridMapper(resource_grid)\n",
    "\n",
    "## Channel\n",
    "cdl = CDL(cdl_model, delay_spread, carrier_frequency,\n",
    "          ut_antenna, bs_array, \"uplink\", min_speed=speed)\n",
    "channel = OFDMChannel(cdl, resource_grid, normalize_channel=True, return_channel=True)\n",
    "\n",
    "## Receiver\n",
    "neural_receiver = NeuralReceiver()\n",
    "rg_demapper = ResourceGridDemapper(resource_grid, stream_manager) # Used to extract data-carrying resource elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf5cfbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c shape:  (64, 1, 1, 2784)\n",
      "x shape:  (64, 1, 1, 1392)\n",
      "x_rg shape:  (64, 1, 1, 14, 128)\n",
      "y shape:  (64, 1, 2, 14, 128)\n",
      "llr shape:  (64, 14, 128, 2)\n",
      "Post RG-demapper LLRs:  (64, 1, 1, 2784)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "ebno_db = tf.fill([batch_size], 5.0)\n",
    "no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n",
    "\n",
    "\n",
    "## Transmitter\n",
    "# Generate codewords\n",
    "c = binary_source([batch_size, 1, 1, n])\n",
    "print(\"c shape: \", c.shape)\n",
    "# Map bits to QAM symbols\n",
    "x = mapper(c)\n",
    "print(\"x shape: \", x.shape)\n",
    "# Map the QAM symbols to a resource grid\n",
    "x_rg = rg_mapper(x)\n",
    "print(\"x_rg shape: \", x_rg.shape)\n",
    "\n",
    "######################################\n",
    "## Channel\n",
    "# A batch of new channel realizations is sampled and applied at every inference\n",
    "no_ = expand_to_rank(no, tf.rank(x_rg))\n",
    "y,_ = channel([x_rg, no_])\n",
    "print(\"y shape: \", y.shape)\n",
    "\n",
    "######################################\n",
    "## Receiver\n",
    "# The neural receiver computes LLRs from the frequency domain received symbols and N0\n",
    "y = tf.squeeze(y, axis=1)\n",
    "llr = neural_receiver([y, no])\n",
    "print(\"llr shape: \", llr.shape)\n",
    "# Reshape the input to fit what the resource grid demapper is expected\n",
    "llr = insert_dims(llr, 2, 1)\n",
    "# Extract data-carrying resource elements. The other LLRs are discarded\n",
    "llr = rg_demapper(llr)\n",
    "llr = tf.reshape(llr, [batch_size, 1, 1, n])\n",
    "print(\"Post RG-demapper LLRs: \", llr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0c0c507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "     -5.0 | 2.5164e-01 | 1.0000e+00 |       44836 |      178176 |          128 |         128 |         3.5 |reached target block errors\n",
      "     -4.5 | 2.3636e-01 | 1.0000e+00 |       42113 |      178176 |          128 |         128 |         0.7 |reached target block errors\n",
      "     -4.0 | 2.1841e-01 | 1.0000e+00 |       38916 |      178176 |          128 |         128 |         0.6 |reached target block errors\n",
      "     -3.5 | 1.9390e-01 | 1.0000e+00 |       34549 |      178176 |          128 |         128 |         0.6 |reached target block errors\n",
      "     -3.0 | 1.6739e-01 | 1.0000e+00 |       29825 |      178176 |          128 |         128 |         0.6 |reached target block errors\n",
      "     -2.5 | 1.0718e-01 | 1.0000e+00 |       19097 |      178176 |          128 |         128 |         0.6 |reached target block errors\n",
      "     -2.0 | 2.0794e-02 | 5.2344e-01 |        7410 |      356352 |          134 |         256 |         1.3 |reached target block errors\n",
      "     -1.5 | 8.3272e-04 | 2.9514e-02 |        4006 |     4810752 |          102 |        3456 |        16.8 |reached target block errors\n",
      "     -1.0 | 1.1601e-04 | 1.6406e-03 |        2067 |    17817600 |           21 |       12800 |        69.9 |reached max iter       \n",
      "     -0.5 | 3.8333e-05 | 4.6875e-04 |         683 |    17817600 |            6 |       12800 |        73.1 |reached max iter       \n",
      "      0.0 | 8.4186e-06 | 7.8125e-05 |         150 |    17817600 |            1 |       12800 |        70.2 |reached max iter       \n",
      "      0.5 | 2.7501e-06 | 7.8125e-05 |          49 |    17817600 |            1 |       12800 |        67.0 |reached max iter       \n",
      "      1.0 | 0.0000e+00 | 0.0000e+00 |           0 |    17817600 |            0 |       12800 |        70.7 |reached max iter       \n",
      "\n",
      "Simulation stopped as no error occurred @ EbNo = 1.0 dB.\n",
      "\n",
      "EbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "     -5.0 | 3.9068e-01 | 1.0000e+00 |       69609 |      178176 |          128 |         128 |         3.9 |reached target block errors\n",
      "     -4.5 | 3.7945e-01 | 1.0000e+00 |       67608 |      178176 |          128 |         128 |         0.7 |reached target block errors\n",
      "     -4.0 | 3.6775e-01 | 1.0000e+00 |       65525 |      178176 |          128 |         128 |         0.7 |reached target block errors\n",
      "     -3.5 | 3.5517e-01 | 1.0000e+00 |       63283 |      178176 |          128 |         128 |         0.8 |reached target block errors\n",
      "     -3.0 | 3.4071e-01 | 1.0000e+00 |       60707 |      178176 |          128 |         128 |         0.8 |reached target block errors\n",
      "     -2.5 | 3.2508e-01 | 1.0000e+00 |       57922 |      178176 |          128 |         128 |         0.8 |reached target block errors\n",
      "     -2.0 | 3.1151e-01 | 1.0000e+00 |       55504 |      178176 |          128 |         128 |         0.7 |reached target block errors\n",
      "     -1.5 | 2.9482e-01 | 1.0000e+00 |       52529 |      178176 |          128 |         128 |         0.8 |reached target block errors\n",
      "     -1.0 | 2.7386e-01 | 1.0000e+00 |       48795 |      178176 |          128 |         128 |         0.8 |reached target block errors\n",
      "     -0.5 | 2.5375e-01 | 1.0000e+00 |       45213 |      178176 |          128 |         128 |         0.7 |reached target block errors\n",
      "      0.0 | 2.3346e-01 | 1.0000e+00 |       41597 |      178176 |          128 |         128 |         0.8 |reached target block errors\n",
      "      0.5 | 2.0558e-01 | 1.0000e+00 |       36630 |      178176 |          128 |         128 |         0.8 |reached target block errors\n",
      "      1.0 | 1.7392e-01 | 1.0000e+00 |       30989 |      178176 |          128 |         128 |         0.7 |reached target block errors\n",
      "      1.5 | 8.4512e-02 | 9.0625e-01 |       15058 |      178176 |          116 |         128 |         0.7 |reached target block errors\n",
      "      2.0 | 1.0267e-02 | 2.3242e-01 |        7317 |      712704 |          119 |         512 |         2.8 |reached target block errors\n",
      "      2.5 | 8.2485e-04 | 1.2019e-02 |        9553 |    11581440 |          100 |        8320 |        45.8 |reached target block errors\n",
      "      3.0 | 2.5632e-04 | 2.1875e-03 |        4567 |    17817600 |           28 |       12800 |        66.5 |reached max iter       \n",
      "      3.5 | 5.4328e-05 | 4.6875e-04 |         968 |    17817600 |            6 |       12800 |        71.7 |reached max iter       \n",
      "      4.0 | 6.1288e-05 | 4.6875e-04 |        1092 |    17817600 |            6 |       12800 |        77.2 |reached max iter       \n",
      "      4.5 | 1.8016e-05 | 1.5625e-04 |         321 |    17817600 |            2 |       12800 |        66.6 |reached max iter       \n",
      "      5.0 | 1.4648e-05 | 7.8125e-05 |         261 |    17817600 |            1 |       12800 |        68.9 |reached max iter       \n",
      "      5.5 | 3.5976e-05 | 1.5625e-04 |         641 |    17817600 |            2 |       12800 |        66.7 |reached max iter       \n",
      "      6.0 | 3.4236e-06 | 7.8125e-05 |          61 |    17817600 |            1 |       12800 |        69.7 |reached max iter       \n",
      "      6.5 | 0.0000e+00 | 0.0000e+00 |           0 |    17817600 |            0 |       12800 |        66.6 |reached max iter       \n",
      "\n",
      "Simulation stopped as no error occurred @ EbNo = 6.5 dB.\n",
      "\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "Exception encountered when calling layer 'e2e_system_3' (type E2ESystem).\n\nin user code:\n\n    File \"/tmp/ipykernel_76648/2518273832.py\", line 226, in call  *\n        llr = self._neural_receiver([y, no])\n    File \"/home/aoschu/anaconda3/envs/OpenNTN/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer 'neural_receiver_1' (type NeuralReceiver).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_76648/2518273832.py\", line 161, in call  *\n            batch_size, num_symbols, num_subc, features = tf.shape(z)\n    \n        OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n    \n    \n    Call arguments received by layer 'neural_receiver_1' (type NeuralReceiver):\n      • inputs=['tf.Tensor(shape=(None, 2, 14, 128), dtype=complex64)', 'tf.Tensor(shape=(None,), dtype=float32)']\n\n\nCall arguments received by layer 'e2e_system_3' (type E2ESystem):\n  • batch_size=tf.Tensor(shape=(), dtype=int32)\n  • ebno_db=tf.Tensor(shape=(), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 256\u001b[0m\n\u001b[1;32m    254\u001b[0m ebno_db \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(shape\u001b[38;5;241m=\u001b[39m[], minval\u001b[38;5;241m=\u001b[39mebno_db_min, maxval\u001b[38;5;241m=\u001b[39mebno_db_max)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m--> 256\u001b[0m     rate \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mebno_db\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mrate\n\u001b[1;32m    258\u001b[0m weights \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrainable_weights  \u001b[38;5;66;03m# Only readout weights are trainable\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/OpenNTN/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/OpenNTN/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:52\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mOperatorNotAllowedInGraphError\u001b[0m: Exception encountered when calling layer 'e2e_system_3' (type E2ESystem).\n\nin user code:\n\n    File \"/tmp/ipykernel_76648/2518273832.py\", line 226, in call  *\n        llr = self._neural_receiver([y, no])\n    File \"/home/aoschu/anaconda3/envs/OpenNTN/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer 'neural_receiver_1' (type NeuralReceiver).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_76648/2518273832.py\", line 161, in call  *\n            batch_size, num_symbols, num_subc, features = tf.shape(z)\n    \n        OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed. You can attempt the following resolutions to the problem: If you are running in Graph mode, use Eager execution mode or decorate this function with @tf.function. If you are using AutoGraph, you can try decorating this function with @tf.function. If that does not work, then you may be using an unsupported feature or your source code may not be visible to AutoGraph. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/limitations.md#access-to-source-code for more information.\n    \n    \n    Call arguments received by layer 'neural_receiver_1' (type NeuralReceiver):\n      • inputs=['tf.Tensor(shape=(None, 2, 14, 128), dtype=complex64)', 'tf.Tensor(shape=(None,), dtype=float32)']\n\n\nCall arguments received by layer 'e2e_system_3' (type E2ESystem):\n  • batch_size=tf.Tensor(shape=(), dtype=int32)\n  • ebno_db=tf.Tensor(shape=(), dtype=float32)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
    "    gpu_num = 0\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    import os\n",
    "    os.system(\"pip install sionna==0.19\")\n",
    "    import sionna\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "sionna.config.seed = 42\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.nn import relu, tanh  # Added tanh for ESN activation\n",
    "\n",
    "from sionna.channel.tr38901 import Antenna, AntennaArray, CDL\n",
    "from sionna.channel import OFDMChannel\n",
    "from sionna.mimo import StreamManagement\n",
    "from sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEEqualizer, RemoveNulledSubcarriers, ResourceGridDemapper\n",
    "from sionna.utils import BinarySource, ebnodb2no, insert_dims, flatten_last_dims, log10, expand_to_rank\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.mapping import Mapper, Demapper\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from sionna.utils import sim_ber\n",
    "\n",
    "carrier_frequency = 3.5e9\n",
    "delay_spread = 100e-9\n",
    "cdl_model = \"C\"\n",
    "speed = 10.0\n",
    "ebno_db_min = -5.0\n",
    "ebno_db_max = 10.0\n",
    "\n",
    "subcarrier_spacing = 30e3\n",
    "fft_size = 128\n",
    "num_ofdm_symbols = 14\n",
    "dc_null = True\n",
    "num_guard_carriers = [5, 6]\n",
    "pilot_pattern = \"kronecker\"\n",
    "pilot_ofdm_symbol_indices = [2, 11]\n",
    "cyclic_prefix_length = 0\n",
    "\n",
    "num_bits_per_symbol = 2\n",
    "coderate = 0.5\n",
    "\n",
    "# ESN hyperparameters (tune these; inspired by papers: units ~ subcarriers, leak=0.1-0.5)\n",
    "esn_units = 256  # Reservoir size\n",
    "leak_rate = 0.1  # Leaky integrator rate\n",
    "spectral_radius = 0.99  # For echo state property\n",
    "\n",
    "num_training_iterations = 30000\n",
    "training_batch_size = 128\n",
    "model_weights_path = \"esn_receiver_weights\"\n",
    "\n",
    "results_filename = \"esn_receiver_results\"\n",
    "\n",
    "stream_manager = StreamManagement(np.array([[1]]), 1)\n",
    "\n",
    "resource_grid = ResourceGrid(num_ofdm_symbols = num_ofdm_symbols,\n",
    "                             fft_size = fft_size,\n",
    "                             subcarrier_spacing = subcarrier_spacing,\n",
    "                             num_tx = 1,\n",
    "                             num_streams_per_tx = 1,\n",
    "                             cyclic_prefix_length = cyclic_prefix_length,\n",
    "                             dc_null = dc_null,\n",
    "                             pilot_pattern = pilot_pattern,\n",
    "                             pilot_ofdm_symbol_indices = pilot_ofdm_symbol_indices,\n",
    "                             num_guard_carriers = num_guard_carriers)\n",
    "\n",
    "n = int(resource_grid.num_data_symbols * num_bits_per_symbol)\n",
    "k = int(n * coderate)\n",
    "\n",
    "ut_antenna = Antenna(polarization=\"single\",\n",
    "                     polarization_type=\"V\",\n",
    "                     antenna_pattern=\"38.901\",\n",
    "                     carrier_frequency=carrier_frequency)\n",
    "\n",
    "bs_array = AntennaArray(num_rows=1,\n",
    "                        num_cols=1,\n",
    "                        polarization=\"dual\",\n",
    "                        polarization_type=\"VH\",\n",
    "                        antenna_pattern=\"38.901\",\n",
    "                        carrier_frequency=carrier_frequency)\n",
    "\n",
    "# New: Define ESNCell as a custom RNN cell (fixed reservoir, trainable readout later)\n",
    "class ESNCell(tf.keras.layers.AbstractRNNCell):\n",
    "    def __init__(self, units, leak_rate, spectral_radius, **kwargs):\n",
    "        super(ESNCell, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.leak_rate = leak_rate\n",
    "        self.spectral_radius = spectral_radius\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self.units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        # Random input weights (fixed)\n",
    "        self.W_in = self.add_weight(shape=(input_dim, self.units),\n",
    "                                    initializer='random_normal',\n",
    "                                    trainable=False,  # Fixed in ESN\n",
    "                                    name='W_in')\n",
    "        # Random reservoir weights (fixed, scaled for spectral radius)\n",
    "        W_res = tf.random.normal([self.units, self.units])\n",
    "        eigvals = tf.linalg.eigvals(W_res)\n",
    "        rho = tf.reduce_max(tf.abs(eigvals))\n",
    "        W_res = W_res * (self.spectral_radius / (rho + 1e-8))  # Avoid div by zero\n",
    "        self.W_res = self.add_weight(shape=(self.units, self.units),\n",
    "                                     initializer=tf.constant_initializer(W_res.numpy()),\n",
    "                                     trainable=False,  # Fixed\n",
    "                                     name='W_res')\n",
    "        # Bias (optional, fixed)\n",
    "        self.bias = self.add_weight(shape=(self.units,),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=False,\n",
    "                                    name='bias')\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        state = states[0]\n",
    "        # ESN update: leaky + tanh (from papers)\n",
    "        pre_activation = tf.matmul(inputs, self.W_in) + tf.matmul(state, self.W_res) + self.bias\n",
    "        new_state = (1 - self.leak_rate) * state + self.leak_rate * tf.tanh(pre_activation)\n",
    "        return new_state, [new_state]\n",
    "\n",
    "# Modified NeuralReceiver using ESN\n",
    "class NeuralReceiver(Layer):\n",
    "    def build(self, input_shape):\n",
    "        # ESN cell\n",
    "        self.esn_cell = ESNCell(units=esn_units, leak_rate=leak_rate, spectral_radius=spectral_radius)\n",
    "        # Trainable readout: Dense to output LLRs (only this is trained)\n",
    "        self.readout = Dense(num_bits_per_symbol, activation=None)  # Linear for logits/LLRs\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y, no = inputs\n",
    "        no = log10(no)\n",
    "        # Transpose to [batch, symbols, subcarriers, rx_ant]\n",
    "        y = tf.transpose(y, [0, 2, 3, 1])\n",
    "        no = insert_dims(no, 3, 1)\n",
    "        no = tf.tile(no, [1, y.shape[1], y.shape[2], 1])\n",
    "        # Concat real/imag/no: [batch, symbols, subcarriers, features=2*rx +1]\n",
    "        z = tf.concat([tf.math.real(y), tf.math.imag(y), no], axis=-1)\n",
    "        # Reshape for RNN: treat symbols as time steps, flatten subcarriers*features as input dim\n",
    "        batch_size, num_symbols, num_subc, features = tf.shape(z)\n",
    "        input_seq = tf.reshape(z, [batch_size, num_symbols, num_subc * features])\n",
    "        # Run ESN RNN over symbols (time)\n",
    "        outputs, _ = tf.keras.layers.RNN(self.esn_cell, return_sequences=True)(input_seq)\n",
    "        # Reshape back: [batch, symbols, subcarriers, esn_units] (approx, may need adjust if not divisible)\n",
    "        outputs = tf.reshape(outputs, [batch_size, num_symbols, num_subc, esn_units])\n",
    "        # Readout to LLRs: [batch, symbols, subcarriers, num_bits_per_symbol]\n",
    "        llr = self.readout(outputs)\n",
    "        return llr\n",
    "\n",
    "# The rest of the code remains the same (E2ESystem, training, evaluation, plotting)\n",
    "# Replace 'neural-receiver' with 'esn-receiver' in model instantiations if desired\n",
    "# Example: model = E2ESystem('neural-receiver', training=True) -> use ESN version above\n",
    "\n",
    "class E2ESystem(Model):\n",
    "    def __init__(self, system, training=False):\n",
    "        super().__init__()\n",
    "        self._system = system\n",
    "        self._training = training\n",
    "        self._binary_source = BinarySource()\n",
    "        if not training:\n",
    "            self._encoder = LDPC5GEncoder(k, n)\n",
    "        self._mapper = Mapper(\"qam\", num_bits_per_symbol)\n",
    "        self._rg_mapper = ResourceGridMapper(resource_grid)\n",
    "        cdl = CDL(cdl_model, delay_spread, carrier_frequency,\n",
    "                  ut_antenna, bs_array, \"uplink\", min_speed=speed)\n",
    "        self._channel = OFDMChannel(cdl, resource_grid, normalize_channel=True, return_channel=True)\n",
    "        if \"baseline\" in system:\n",
    "            if system == 'baseline-perfect-csi':\n",
    "                self._removed_null_subc = RemoveNulledSubcarriers(resource_grid)\n",
    "            elif system == 'baseline-ls-estimation':\n",
    "                self._ls_est = LSChannelEstimator(resource_grid, interpolation_type=\"nn\")\n",
    "            self._lmmse_equ = LMMSEEqualizer(resource_grid, stream_manager)\n",
    "            self._demapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n",
    "        elif system == \"neural-receiver\":  # Now ESN-based\n",
    "            self._neural_receiver = NeuralReceiver()\n",
    "            self._rg_demapper = ResourceGridDemapper(resource_grid, stream_manager)\n",
    "        if not training:\n",
    "            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, batch_size, ebno_db):\n",
    "        if len(ebno_db.shape) == 0:\n",
    "            ebno_db = tf.fill([batch_size], ebno_db)\n",
    "        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n",
    "        if self._training:\n",
    "            c = self._binary_source([batch_size, 1, 1, n])\n",
    "        else:\n",
    "            b = self._binary_source([batch_size, 1, 1, k])\n",
    "            c = self._encoder(b)\n",
    "        x = self._mapper(c)\n",
    "        x_rg = self._rg_mapper(x)\n",
    "        no_ = expand_to_rank(no, tf.rank(x_rg))\n",
    "        y, h = self._channel([x_rg, no_])\n",
    "        if \"baseline\" in self._system:\n",
    "            if self._system == 'baseline-perfect-csi':\n",
    "                h_hat = self._removed_null_subc(h)\n",
    "                err_var = 0.0\n",
    "            elif self._system == 'baseline-ls-estimation':\n",
    "                h_hat, err_var = self._ls_est([y, no])\n",
    "            x_hat, no_eff = self._lmmse_equ([y, h_hat, err_var, no])\n",
    "            no_eff_ = expand_to_rank(no_eff, tf.rank(x_hat))\n",
    "            llr = self._demapper([x_hat, no_eff_])\n",
    "        elif self._system == \"neural-receiver\":\n",
    "            y = tf.squeeze(y, axis=1)\n",
    "            llr = self._neural_receiver([y, no])\n",
    "            llr = insert_dims(llr, 2, 1)\n",
    "            llr = self._rg_demapper(llr)\n",
    "            llr = tf.reshape(llr, [batch_size, 1, 1, n])\n",
    "        if self._training:\n",
    "            bce = tf.nn.sigmoid_cross_entropy_with_logits(c, llr)\n",
    "            bce = tf.reduce_mean(bce)\n",
    "            rate = tf.constant(1.0, tf.float32) - bce / tf.math.log(2.)\n",
    "            return rate\n",
    "        else:\n",
    "            b_hat = self._decoder(llr)\n",
    "            return b, b_hat\n",
    "\n",
    "ebno_dbs = np.arange(ebno_db_min, ebno_db_max + 0.5, 0.5)\n",
    "\n",
    "BLER = {}\n",
    "\n",
    "model = E2ESystem('baseline-perfect-csi')\n",
    "_, bler = sim_ber(model, ebno_dbs, batch_size=128, num_target_block_errors=100, max_mc_iter=100)\n",
    "BLER['baseline-perfect-csi'] = bler.numpy()\n",
    "\n",
    "model = E2ESystem('baseline-ls-estimation')\n",
    "_, bler = sim_ber(model, ebno_dbs, batch_size=128, num_target_block_errors=100, max_mc_iter=100)\n",
    "BLER['baseline-ls-estimation'] = bler.numpy()\n",
    "\n",
    "model = E2ESystem('neural-receiver', training=True)  # Now ESN\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "for i in range(num_training_iterations):\n",
    "    ebno_db = tf.random.uniform(shape=[], minval=ebno_db_min, maxval=ebno_db_max)\n",
    "    with tf.GradientTape() as tape:\n",
    "        rate = model(training_batch_size, ebno_db)\n",
    "        loss = -rate\n",
    "    weights = model.trainable_weights  # Only readout weights are trainable\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    optimizer.apply_gradients(zip(grads, weights))\n",
    "    if i % 100 == 0:\n",
    "        print('Iteration {}/{}  Rate: {:.4f} bit'.format(i, num_training_iterations, rate.numpy()), end='\\r')\n",
    "\n",
    "weights = model.get_weights()\n",
    "with open(model_weights_path, 'wb') as f:\n",
    "    pickle.dump(weights, f)\n",
    "\n",
    "model = E2ESystem('neural-receiver')\n",
    "model(1, tf.constant(10.0, tf.float32))\n",
    "with open(model_weights_path, 'rb') as f:\n",
    "    weights = pickle.load(f)\n",
    "model.set_weights(weights)\n",
    "\n",
    "_, bler = sim_ber(model, ebno_dbs, batch_size=128, num_target_block_errors=100, max_mc_iter=100)\n",
    "BLER['neural-receiver'] = bler.numpy()  # Now ESN results\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.semilogy(ebno_dbs, BLER['baseline-perfect-csi'], 'o-', c='C0', label='Baseline - Perfect CSI')\n",
    "plt.semilogy(ebno_dbs, BLER['baseline-ls-estimation'], 'x--', c='C1', label='Baseline - LS Estimation')\n",
    "plt.semilogy(ebno_dbs, BLER['neural-receiver'], 's-.', c='C2', label='ESN receiver')\n",
    "plt.xlabel(r\"$E_b/N_0$ (dB)\")\n",
    "plt.ylabel(\"BLER\")\n",
    "plt.grid(which=\"both\")\n",
    "plt.ylim((1e-4, 1.0))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1478d1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "      1.0 | 5.0017e-01 | 1.0000e+00 |       89118 |      178176 |          128 |         128 |         0.6 |reached target block errors\n",
      "      2.0 | 4.9784e-01 | 1.0000e+00 |       88703 |      178176 |          128 |         128 |         0.6 |reached target block errors\n",
      "      3.0 | 4.9969e-01 | 1.0000e+00 |       89033 |      178176 |          128 |         128 |         0.6 |reached target block errors\n",
      "      4.0 | 5.0180e-01 | 1.0000e+00 |       89409 |      178176 |          128 |         128 |         0.5 |reached target block errors\n",
      "      5.0 | 5.0028e-01 | 1.0000e+00 |       89137 |      178176 |          128 |         128 |         0.5 |reached target block errors\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
    "    gpu_num = 0\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    import os\n",
    "    os.system(\"pip install sionna==0.19\")\n",
    "    import sionna\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "sionna.config.seed = 42\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.nn import relu, tanh\n",
    "\n",
    "from sionna.channel.tr38901 import Antenna, AntennaArray, CDL\n",
    "from sionna.channel import OFDMChannel\n",
    "from sionna.mimo import StreamManagement\n",
    "from sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEEqualizer, RemoveNulledSubcarriers, ResourceGridDemapper\n",
    "from sionna.utils import BinarySource, ebnodb2no, insert_dims, flatten_last_dims, log10, expand_to_rank\n",
    "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
    "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
    "from sionna.mapping import Mapper, Demapper\n",
    "from sionna.utils.metrics import compute_ber\n",
    "from sionna.utils import sim_ber\n",
    "\n",
    "carrier_frequency = 3.5e9\n",
    "delay_spread = 100e-9\n",
    "cdl_model = \"C\"\n",
    "speed = 10.0\n",
    "ebno_db_min = -5.0\n",
    "ebno_db_max = 10.0\n",
    "\n",
    "subcarrier_spacing = 30e3\n",
    "fft_size = 128\n",
    "num_ofdm_symbols = 14\n",
    "dc_null = True\n",
    "num_guard_carriers = [5, 6]\n",
    "pilot_pattern = \"kronecker\"\n",
    "pilot_ofdm_symbol_indices = [2, 11]\n",
    "cyclic_prefix_length = 0\n",
    "\n",
    "num_bits_per_symbol = 2\n",
    "coderate = 0.5\n",
    "\n",
    "esn_units = 256\n",
    "leak_rate = 0.1\n",
    "spectral_radius = 0.99\n",
    "\n",
    "num_training_iterations = 3000\n",
    "training_batch_size = 128\n",
    "model_weights_path = \"esn_receiver_weights\"\n",
    "\n",
    "results_filename = \"esn_receiver_results\"\n",
    "\n",
    "stream_manager = StreamManagement(np.array([[1]]), 1)\n",
    "\n",
    "resource_grid = ResourceGrid(num_ofdm_symbols = num_ofdm_symbols,\n",
    "                             fft_size = fft_size,\n",
    "                             subcarrier_spacing = subcarrier_spacing,\n",
    "                             num_tx = 1,\n",
    "                             num_streams_per_tx = 1,\n",
    "                             cyclic_prefix_length = cyclic_prefix_length,\n",
    "                             dc_null = dc_null,\n",
    "                             pilot_pattern = pilot_pattern,\n",
    "                             pilot_ofdm_symbol_indices = pilot_ofdm_symbol_indices,\n",
    "                             num_guard_carriers = num_guard_carriers)\n",
    "\n",
    "n = int(resource_grid.num_data_symbols * num_bits_per_symbol)\n",
    "k = int(n * coderate)\n",
    "\n",
    "ut_antenna = Antenna(polarization=\"single\",\n",
    "                     polarization_type=\"V\",\n",
    "                     antenna_pattern=\"38.901\",\n",
    "                     carrier_frequency=carrier_frequency)\n",
    "\n",
    "bs_array = AntennaArray(num_rows=1,\n",
    "                        num_cols=1,\n",
    "                        polarization=\"dual\",\n",
    "                        polarization_type=\"VH\",\n",
    "                        antenna_pattern=\"38.901\",\n",
    "                        carrier_frequency=carrier_frequency)\n",
    "\n",
    "class NeuralReceiver(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.readout = Dense(num_bits_per_symbol, activation=None)\n",
    "        # Precompute fixed weights\n",
    "        self.sw = tf.Variable(1.0, trainable=True)  # Scalable if needed\n",
    "        self.rho = tf.Variable(1.0, trainable=True)\n",
    "        self.decay_var = tf.Variable(leak_rate, trainable=True)\n",
    "        self.alpha_var = tf.Variable(0.5, trainable=True)\n",
    "        rng = np.random.RandomState(42)\n",
    "        self.w_in = tf.constant(rng.normal(size=(fft_size * 5, esn_units)), dtype=tf.float32)  # Input dim = 128*5 = 640\n",
    "        w_res_np = rng.normal(size=(esn_units, esn_units))\n",
    "        eigvals_np = np.linalg.eigvals(w_res_np)\n",
    "        rho_np = np.max(np.abs(eigvals_np))\n",
    "        w_res_scaled = w_res_np * (spectral_radius / (rho_np + 1e-8))\n",
    "        self.w_res = tf.constant(w_res_scaled, dtype=tf.float32)\n",
    "        self.bias = tf.zeros((esn_units,))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y, no = inputs\n",
    "        no = log10(no)\n",
    "        y = tf.transpose(y, [0, 2, 3, 1])  # [batch, symbols=14, subcarriers=128, rx=2]\n",
    "        no = insert_dims(no, 3, 1)\n",
    "        no = tf.tile(no, [1, num_ofdm_symbols, fft_size, 1])\n",
    "        z = tf.concat([tf.math.real(y), tf.math.imag(y), no], axis=-1)  # [batch, 14, 128, 5]\n",
    "        batch_size = tf.shape(z)[0]\n",
    "        z = tf.reshape(z, [batch_size, num_ofdm_symbols, fft_size * 5])  # [batch, 14, 640]\n",
    "\n",
    "        # Initialize state\n",
    "        state = tf.zeros([batch_size, esn_units])\n",
    "        outputs = []\n",
    "        for t in range(num_ofdm_symbols):\n",
    "            inputs_t = z[:, t, :] * self.sw\n",
    "            pre_activation = tf.matmul(inputs_t, self.w_in) + tf.matmul(state, self.w_res) + self.bias\n",
    "            new_state = (1 - self.decay_var) * state + self.decay_var * tanh(self.alpha_var * pre_activation)\n",
    "            outputs.append(new_state)\n",
    "            state = new_state\n",
    "        outputs = tf.stack(outputs, axis=1)  # [batch, 14, esn_units]\n",
    "        outputs = tf.reshape(outputs, [batch_size, num_ofdm_symbols, fft_size, esn_units // fft_size]) if esn_units % fft_size == 0 else outputs[:, :, None, :]  # Adjust if needed, but for 256/128=2, reshape to [batch, 14, 128, 2]\n",
    "        # If esn_units not divisible, keep as is and adjust readout\n",
    "        llr = self.readout(outputs)  # Apply readout to [batch, 14, 128, esn_units] -> [batch, 14, 128, 2]\n",
    "        return llr\n",
    "\n",
    "class E2ESystem(Model):\n",
    "    def __init__(self, system, training=False):\n",
    "        super().__init__()\n",
    "        self._system = system\n",
    "        self._training = training\n",
    "        self._binary_source = BinarySource()\n",
    "        if not training:\n",
    "            self._encoder = LDPC5GEncoder(k, n)\n",
    "        self._mapper = Mapper(\"qam\", num_bits_per_symbol)\n",
    "        self._rg_mapper = ResourceGridMapper(resource_grid)\n",
    "        cdl = CDL(cdl_model, delay_spread, carrier_frequency,\n",
    "                  ut_antenna, bs_array, \"uplink\", min_speed=speed)\n",
    "        self._channel = OFDMChannel(cdl, resource_grid, normalize_channel=True, return_channel=True)\n",
    "        if \"baseline\" in system:\n",
    "            if system == 'baseline-perfect-csi':\n",
    "                self._removed_null_subc = RemoveNulledSubcarriers(resource_grid)\n",
    "            elif system == 'baseline-ls-estimation':\n",
    "                self._ls_est = LSChannelEstimator(resource_grid, interpolation_type=\"nn\")\n",
    "            self._lmmse_equ = LMMSEEqualizer(resource_grid, stream_manager)\n",
    "            self._demapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n",
    "        elif system == \"neural-receiver\":\n",
    "            self._neural_receiver = NeuralReceiver()\n",
    "            self._rg_demapper = ResourceGridDemapper(resource_grid, stream_manager)\n",
    "        if not training:\n",
    "            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n",
    "\n",
    "    @tf.function(jit_compile=False)\n",
    "    def call(self, batch_size, ebno_db):\n",
    "        if len(ebno_db.shape) == 0:\n",
    "            ebno_db = tf.fill([batch_size], ebno_db)\n",
    "        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n",
    "        if self._training:\n",
    "            c = self._binary_source([batch_size, 1, 1, n])\n",
    "        else:\n",
    "            b = self._binary_source([batch_size, 1, 1, k])\n",
    "            c = self._encoder(b)\n",
    "        x = self._mapper(c)\n",
    "        x_rg = self._rg_mapper(x)\n",
    "        no_ = expand_to_rank(no, tf.rank(x_rg))\n",
    "        y, h = self._channel([x_rg, no_])\n",
    "        if \"baseline\" in self._system:\n",
    "            if self._system == 'baseline-perfect-csi':\n",
    "                h_hat = self._removed_null_subc(h)\n",
    "                err_var = 0.0\n",
    "            elif self._system == 'baseline-ls-estimation':\n",
    "                h_hat, err_var = self._ls_est([y, no])\n",
    "            x_hat, no_eff = self._lmmse_equ([y, h_hat, err_var, no])\n",
    "            no_eff_ = expand_to_rank(no_eff, tf.rank(x_hat))\n",
    "            llr = self._demapper([x_hat, no_eff_])\n",
    "        elif self._system == \"neural-receiver\":\n",
    "            y = tf.squeeze(y, axis=1)\n",
    "            llr = self._neural_receiver([y, no])\n",
    "            llr = insert_dims(llr, 2, 1)\n",
    "            llr = self._rg_demapper(llr)\n",
    "            llr = tf.reshape(llr, [batch_size, 1, 1, n])\n",
    "        if self._training:\n",
    "            bce = tf.nn.sigmoid_cross_entropy_with_logits(c, llr)\n",
    "            bce = tf.reduce_mean(bce)\n",
    "            rate = tf.constant(1.0, tf.float32) - bce / tf.math.log(2.)\n",
    "            return rate\n",
    "        else:\n",
    "            b_hat = self._decoder(llr)\n",
    "            return b, b_hat\n",
    "\n",
    "ebno_dbs = np.arange(1, 5 + 0.5, 1)\n",
    "\n",
    "BLER = {}\n",
    "\"\"\"\n",
    "model = E2ESystem('baseline-perfect-csi')\n",
    "_, bler = sim_ber(model, ebno_dbs, batch_size=128, num_target_block_errors=100, max_mc_iter=100)\n",
    "BLER['baseline-perfect-csi'] = bler.numpy()\n",
    "\n",
    "model = E2ESystem('baseline-ls-estimation')\n",
    "_, bler = sim_ber(model, ebno_dbs, batch_size=128, num_target_block_errors=100, max_mc_iter=100)\n",
    "BLER['baseline-ls-estimation'] = bler.numpy()\n",
    "\"\"\"\n",
    "model = E2ESystem('neural-receiver', training=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "for i in range(num_training_iterations):\n",
    "    ebno_db = tf.random.uniform(shape=[], minval=ebno_db_min, maxval=ebno_db_max)\n",
    "    with tf.GradientTape() as tape:\n",
    "        rate = model(training_batch_size, ebno_db)\n",
    "        loss = -rate\n",
    "    weights = model.trainable_weights\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    optimizer.apply_gradients(zip(grads, weights))\n",
    "    if i % 100 == 0:\n",
    "        print('Iteration {}/{}  Rate: {:.4f} bit'.format(i, num_training_iterations, rate.numpy()), end='\\r')\n",
    "\n",
    "weights = model.get_weights()\n",
    "with open(model_weights_path, 'wb') as f:\n",
    "    pickle.dump(weights, f)\n",
    "\n",
    "model = E2ESystem('neural-receiver')\n",
    "model(1, tf.constant(10.0, tf.float32))\n",
    "with open(model_weights_path, 'rb') as f:\n",
    "    weights = pickle.load(f)\n",
    "model.set_weights(weights)\n",
    "\n",
    "_, bler = sim_ber(model, ebno_dbs, batch_size=128, num_target_block_errors=100, max_mc_iter=100)\n",
    "BLER['neural-receiver'] = bler.numpy()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "#plt.semilogy(ebno_dbs, BLER['baseline-perfect-csi'], 'o-', c='C0', label='Baseline - Perfect CSI')\n",
    "#plt.semilogy(ebno_dbs, BLER['baseline-ls-estimation'], 'x--', c='C1', label='Baseline - LS Estimation')\n",
    "plt.semilogy(ebno_dbs, BLER['neural-receiver'], 's-.', c='C2', label='ESN receiver')\n",
    "plt.xlabel(r\"$E_b/N_0$ (dB)\")\n",
    "plt.ylabel(\"BLER\")\n",
    "plt.grid(which=\"both\")\n",
    "plt.ylim((1e-4, 1.0))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61bb614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape before squeeze: [128 1 1 14 128]\n",
      "y shape before neural receiver: [128 1 14 128]\n",
      "y shape: [128 1 14 128]\n",
      "no shape: [128]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'neural_receiver_2' (type NeuralReceiver).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Dimension 1 in both shapes must be equal: shape[0] = [128,1,14,256] vs. shape[1] = [128,14,128,1] [Op:ConcatV2] name: concat\n\nCall arguments received by layer 'neural_receiver_2' (type NeuralReceiver):\n  • inputs=['tf.Tensor(shape=(128, 1, 14, 128), dtype=complex64)', 'tf.Tensor(shape=(128,), dtype=float32)']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 205\u001b[0m\n\u001b[1;32m    203\u001b[0m ebno_db \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(shape\u001b[38;5;241m=\u001b[39m[], minval\u001b[38;5;241m=\u001b[39mebno_db_min, maxval\u001b[38;5;241m=\u001b[39mebno_db_max)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m--> 205\u001b[0m     rate \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mebno_db\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mrate\n\u001b[1;32m    207\u001b[0m weights \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrainable_weights\n",
      "File \u001b[0;32m~/anaconda3/envs/OpenNTN/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[3], line 182\u001b[0m, in \u001b[0;36mE2ESystem.call\u001b[0;34m(self, batch_size, ebno_db)\u001b[0m\n\u001b[1;32m    180\u001b[0m y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Remove num_streams_per_tx dimension\u001b[39;00m\n\u001b[1;32m    181\u001b[0m tf\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my shape before neural receiver:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39mshape(y))  \u001b[38;5;66;03m# Debug: Should be [batch, 1, 14, 128]\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m llr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_neural_receiver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m llr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(llr, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    184\u001b[0m llr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtranspose(llr, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m])\n",
      "Cell \u001b[0;32mIn[3], line 134\u001b[0m, in \u001b[0;36mNeuralReceiver.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    132\u001b[0m no \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(no, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    133\u001b[0m no \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtile(no, [\u001b[38;5;241m1\u001b[39m, NUM_OFDM_SYMBOLS, FFT_SIZE, \u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# [batch, ofdm, fft, 1]\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_ri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, ofdm, fft, 2*rx_ant + 1]\u001b[39;00m\n\u001b[1;32m    135\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mshape(z)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    136\u001b[0m z \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreshape(z, [batch_size, NUM_OFDM_SYMBOLS, FFT_SIZE \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m NUM_RX_ANT \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])  \u001b[38;5;66;03m# [batch, ofdm, 384]\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'neural_receiver_2' (type NeuralReceiver).\n\n{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Dimension 1 in both shapes must be equal: shape[0] = [128,1,14,256] vs. shape[1] = [128,14,128,1] [Op:ConcatV2] name: concat\n\nCall arguments received by layer 'neural_receiver_2' (type NeuralReceiver):\n  • inputs=['tf.Tensor(shape=(128, 1, 14, 128), dtype=complex64)', 'tf.Tensor(shape=(128,), dtype=float32)']"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
    "    gpu_num = 0\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "try:\n",
    "    import sionna\n",
    "except ImportError as e:\n",
    "    import os\n",
    "    os.system(\"pip install sionna==0.19.2\")\n",
    "    import sionna\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "sionna.config.seed = 42\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "from tensorflow.nn import tanh\n",
    "\n",
    "from sionna.mimo import StreamManagement\n",
    "from sionna.utils import BinarySource, sim_ber, ebnodb2no\n",
    "from sionna.mapping import Mapper\n",
    "from sionna.ofdm import ResourceGrid, ResourceGridMapper, ResourceGridDemapper\n",
    "from sionna.channel import OFDMChannel\n",
    "from sionna.channel.tr38901 import CDL, Antenna\n",
    "from sionna.fec.ldpc import LDPC5GEncoder, LDPC5GDecoder\n",
    "\n",
    "# Simulation parameters\n",
    "NUM_OFDM_SYMBOLS = 14\n",
    "FFT_SIZE = 128\n",
    "SUBCARRIER_SPACING = 30e3  # Hz\n",
    "CARRIER_FREQUENCY = 3.5e9  # Hz\n",
    "SPEED = 10.0  # m/s\n",
    "DELAY_SPREAD = 100e-9\n",
    "CDL_MODEL = \"C\"\n",
    "\n",
    "NUM_TX = 1\n",
    "NUM_RX_ANT = 1  # SISO configuration\n",
    "NUM_BITS_PER_SYMBOL = 2  # QPSK\n",
    "CODERATE = 0.5\n",
    "\n",
    "esn_units = 256\n",
    "leak_rate = 0.1\n",
    "spectral_radius = 0.99\n",
    "num_training_iterations = 3000\n",
    "training_batch_size = 128\n",
    "model_weights_path = \"esn_siso_cdl_weights\"\n",
    "ebno_db_min = -5.0\n",
    "ebno_db_max = 10.0\n",
    "EBN0_DBs = np.linspace(1.0, 5.0, 5)\n",
    "\n",
    "# Antenna configuration\n",
    "UT_ANTENNA = Antenna(polarization=\"single\",\n",
    "                     polarization_type=\"V\",\n",
    "                     antenna_pattern=\"38.901\",\n",
    "                     carrier_frequency=CARRIER_FREQUENCY)\n",
    "\n",
    "BS_ANTENNA = Antenna(polarization=\"single\",\n",
    "                     polarization_type=\"V\",\n",
    "                     antenna_pattern=\"38.901\",\n",
    "                     carrier_frequency=CARRIER_FREQUENCY)\n",
    "\n",
    "# CDL channel model\n",
    "CHANNEL_MODEL = CDL(model=CDL_MODEL,\n",
    "                    delay_spread=DELAY_SPREAD,\n",
    "                    carrier_frequency=CARRIER_FREQUENCY,\n",
    "                    ut_array=UT_ANTENNA,\n",
    "                    bs_array=BS_ANTENNA,\n",
    "                    direction=\"uplink\",\n",
    "                    min_speed=SPEED)\n",
    "\n",
    "# Resource grid\n",
    "rg = ResourceGrid(num_ofdm_symbols=NUM_OFDM_SYMBOLS,\n",
    "                  fft_size=FFT_SIZE,\n",
    "                  subcarrier_spacing=SUBCARRIER_SPACING,\n",
    "                  num_tx=NUM_TX,\n",
    "                  num_streams_per_tx=1,\n",
    "                  cyclic_prefix_length=0,\n",
    "                  dc_null=True,\n",
    "                  pilot_pattern=\"kronecker\",\n",
    "                  pilot_ofdm_symbol_indices=[2,11],\n",
    "                  num_guard_carriers=[5,6])\n",
    "\n",
    "# Stream management\n",
    "sm = StreamManagement(np.array([[1]]), 1)\n",
    "\n",
    "# Codeword length and number of information bits\n",
    "n = int(rg.num_data_symbols * NUM_BITS_PER_SYMBOL)\n",
    "k = int(n * CODERATE)\n",
    "\n",
    "class NeuralReceiver(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.readout = Dense(NUM_BITS_PER_SYMBOL, activation=None)\n",
    "        self.sw = tf.Variable(1.0, trainable=True)\n",
    "        self.decay_var = tf.Variable(leak_rate, trainable=True)\n",
    "        self.alpha_var = tf.Variable(0.5, trainable=True)\n",
    "        rng = np.random.RandomState(42)\n",
    "        input_dim = FFT_SIZE * (2 * NUM_RX_ANT + 1)  # Real, Imag, Noise = 128 * 3 = 384\n",
    "        self.w_in = tf.constant(rng.normal(size=(input_dim, esn_units)), dtype=tf.float32)\n",
    "        w_res_np = rng.normal(size=(esn_units, esn_units))\n",
    "        eigvals_np = np.linalg.eigvals(w_res_np)\n",
    "        rho_np = np.max(np.abs(eigvals_np))\n",
    "        w_res_scaled = w_res_np * (spectral_radius / (rho_np + 1e-8))\n",
    "        self.w_res = tf.constant(w_res_scaled, dtype=tf.float32)\n",
    "        self.bias = tf.zeros((esn_units,))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y, no = inputs\n",
    "        tf.print(\"y shape:\", tf.shape(y))  # Debug: Should be [batch, 14, 128, 1]\n",
    "        tf.print(\"no shape:\", tf.shape(no))  # Debug: Should be [batch]\n",
    "        no = tf.math.log(no) / tf.math.log(10.0)  # Workaround for log10\n",
    "        y = tf.transpose(y, [0, 1, 2, 3])  # [batch, ofdm, fft, rx_ant]\n",
    "        y_real = tf.math.real(y)\n",
    "        y_imag = tf.math.imag(y)\n",
    "        y_ri = tf.concat([y_real, y_imag], axis=-1)  # [batch, ofdm, fft, 2*rx_ant]\n",
    "        no = tf.expand_dims(no, axis=1)\n",
    "        no = tf.expand_dims(no, axis=1)\n",
    "        no = tf.expand_dims(no, axis=1)\n",
    "        no = tf.tile(no, [1, NUM_OFDM_SYMBOLS, FFT_SIZE, 1])  # [batch, ofdm, fft, 1]\n",
    "        z = tf.concat([y_ri, no], axis=-1)  # [batch, ofdm, fft, 2*rx_ant + 1]\n",
    "        batch_size = tf.shape(z)[0]\n",
    "        z = tf.reshape(z, [batch_size, NUM_OFDM_SYMBOLS, FFT_SIZE * (2 * NUM_RX_ANT + 1)])  # [batch, ofdm, 384]\n",
    "        state = tf.zeros([batch_size, esn_units])\n",
    "        outputs = []\n",
    "        for t in range(NUM_OFDM_SYMBOLS):\n",
    "            inputs_t = z[:, t, :] * self.sw\n",
    "            pre_activation = tf.matmul(inputs_t, self.w_in) + tf.matmul(state, self.w_res) + self.bias\n",
    "            new_state = (1 - self.decay_var) * state + self.decay_var * tanh(self.alpha_var * pre_activation)\n",
    "            outputs.append(new_state)\n",
    "            state = new_state\n",
    "        outputs = tf.stack(outputs, axis=1)  # [batch, ofdm, esn_units]\n",
    "        outputs = tf.reshape(outputs, [batch_size, NUM_OFDM_SYMBOLS, FFT_SIZE, esn_units // FFT_SIZE])  # [batch, ofdm, fft, 2]\n",
    "        llr = self.readout(outputs)  # [batch, ofdm, fft, num_bits_per_symbol]\n",
    "        tf.print(\"llr shape:\", tf.shape(llr))  # Debug: Should be [batch, 14, 128, 2]\n",
    "        return llr\n",
    "\n",
    "class E2ESystem(Model):\n",
    "    def __init__(self, training=False):\n",
    "        super().__init__()\n",
    "        self._training = training\n",
    "        self._binary_source = BinarySource()\n",
    "        if not training:\n",
    "            self._encoder = LDPC5GEncoder(k, n, num_bits_per_symbol=NUM_BITS_PER_SYMBOL)\n",
    "        self._mapper = Mapper(constellation_type=\"qam\", num_bits_per_symbol=NUM_BITS_PER_SYMBOL)\n",
    "        self._rg_mapper = ResourceGridMapper(rg)\n",
    "        self._channel = OFDMChannel(CHANNEL_MODEL, rg, normalize_channel=True, return_channel=True)\n",
    "        self._neural_receiver = NeuralReceiver()\n",
    "        self._rg_demapper = ResourceGridDemapper(rg, sm)\n",
    "        if not training:\n",
    "            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n",
    "\n",
    "    def call(self, batch_size, ebno_db):\n",
    "        if tf.rank(ebno_db) == 0:\n",
    "            ebno_db = tf.fill([batch_size], ebno_db)\n",
    "        no = ebnodb2no(ebno_db, NUM_BITS_PER_SYMBOL, CODERATE, resource_grid=rg)\n",
    "        if self._training:\n",
    "            c = self._binary_source([batch_size, NUM_TX, 1, n])\n",
    "        else:\n",
    "            b = self._binary_source([batch_size, NUM_TX, 1, k])\n",
    "            c = self._encoder(b)\n",
    "        x = self._mapper(c)\n",
    "        x_rg = self._rg_mapper(x)\n",
    "        no_ = tf.cast(tf.expand_dims(no, axis=-1), tf.float32)\n",
    "        y, h = self._channel([x_rg, no_])\n",
    "        tf.print(\"y shape before squeeze:\", tf.shape(y))  # Debug: Should be [batch, 1, 1, 14, 128]\n",
    "        y = tf.squeeze(y, axis=2)  # Remove num_streams_per_tx dimension\n",
    "        tf.print(\"y shape before neural receiver:\", tf.shape(y))  # Debug: Should be [batch, 1, 14, 128]\n",
    "        llr = self._neural_receiver([y, no])\n",
    "        llr = tf.expand_dims(llr, axis=3)\n",
    "        llr = tf.transpose(llr, [0, 3, 1, 2, 4])\n",
    "        tf.print(\"llr shape before demapper:\", tf.shape(llr))  # Debug: Should be [batch, 1, 14, 128, 2]\n",
    "        llr = self._rg_demapper(llr)\n",
    "        llr = tf.reshape(llr, [batch_size, NUM_TX, 1, n])\n",
    "        tf.print(\"llr shape after demapper:\", tf.shape(llr))  # Debug: Should be [batch, 1, 1, n]\n",
    "        if self._training:\n",
    "            bce = tf.nn.sigmoid_cross_entropy_with_logits(c, llr)\n",
    "            bce = tf.reduce_mean(bce)\n",
    "            rate = tf.constant(1.0, tf.float32) - bce / tf.math.log(2.0)\n",
    "            tf.print(\"rate:\", rate)  # Debug: Should increase during training\n",
    "            return rate\n",
    "        else:\n",
    "            b_hat = self._decoder(llr)\n",
    "            return b, b_hat\n",
    "\n",
    "# Train the neural receiver\n",
    "model = E2ESystem(training=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "for i in range(num_training_iterations):\n",
    "    ebno_db = tf.random.uniform(shape=[], minval=ebno_db_min, maxval=ebno_db_max)\n",
    "    with tf.GradientTape() as tape:\n",
    "        rate = model(training_batch_size, ebno_db)\n",
    "        loss = -rate\n",
    "    weights = model.trainable_weights\n",
    "    grads = tape.gradient(loss, weights)\n",
    "    optimizer.apply_gradients(zip(grads, weights))\n",
    "    if i % 100 == 0:\n",
    "        print(f'Iteration {i}/{num_training_iterations}  Rate: {rate.numpy():.4f} bit', end='\\r')\n",
    "\n",
    "weights = model.get_weights()\n",
    "with open(model_weights_path, 'wb') as f:\n",
    "    pickle.dump(weights, f)\n",
    "\n",
    "# Evaluate\n",
    "model = E2ESystem(training=False)\n",
    "model(1, tf.constant(10.0, tf.float32))\n",
    "with open(model_weights_path, 'rb') as f:\n",
    "    weights = pickle.load(f)\n",
    "model.set_weights(weights)\n",
    "\n",
    "_, bler = sim_ber(model, EBN0_DBs, batch_size=128, num_target_block_errors=100, max_mc_iter=100)\n",
    "BLER = {'Neural ESN': bler.numpy()}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.semilogy(EBN0_DBs, BLER['Neural ESN'], 's-.', c='C2', label='Neural ESN')\n",
    "plt.xlabel(r\"$E_b/N_0$ (dB)\")\n",
    "plt.ylabel(\"BLER\")\n",
    "plt.grid(which=\"both\")\n",
    "plt.ylim((1e-4, 1.0))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7fa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e59d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae80326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenNTN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
